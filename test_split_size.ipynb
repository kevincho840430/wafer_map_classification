{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('LSWMD.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>waferMap</th>\n",
       "      <th>dieSize</th>\n",
       "      <th>lotName</th>\n",
       "      <th>waferIndex</th>\n",
       "      <th>trianTestLabel</th>\n",
       "      <th>failureType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>1683.0</td>\n",
       "      <td>lot1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[Training]]</td>\n",
       "      <td>[[none]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>1683.0</td>\n",
       "      <td>lot1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[[Training]]</td>\n",
       "      <td>[[none]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>1683.0</td>\n",
       "      <td>lot1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[[Training]]</td>\n",
       "      <td>[[none]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>1683.0</td>\n",
       "      <td>lot1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[[Training]]</td>\n",
       "      <td>[[none]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>1683.0</td>\n",
       "      <td>lot1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[[Training]]</td>\n",
       "      <td>[[none]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            waferMap  dieSize lotName  \\\n",
       "0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   1683.0    lot1   \n",
       "1  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   1683.0    lot1   \n",
       "2  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   1683.0    lot1   \n",
       "3  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   1683.0    lot1   \n",
       "4  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   1683.0    lot1   \n",
       "\n",
       "   waferIndex trianTestLabel failureType  \n",
       "0         1.0   [[Training]]    [[none]]  \n",
       "1         2.0   [[Training]]    [[none]]  \n",
       "2         3.0   [[Training]]    [[none]]  \n",
       "3         4.0   [[Training]]    [[none]]  \n",
       "4         5.0   [[Training]]    [[none]]  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.astype({\"trianTestLabel\": str, \"failureType\":str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"[['none']]\", \"[['Loc']]\", '[]', \"[['Edge-Loc']]\", \"[['Center']]\",\n",
       "       \"[['Edge-Ring']]\", \"[['Scratch']]\", \"[['Random']]\",\n",
       "       \"[['Near-full']]\", \"[['Donut']]\"], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"failureType\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_names = df[(df[\"failureType\"] == \"[['none']]\") | (df[\"failureType\"] == \"[]\")].index\n",
    "df = df.drop(index_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"[['Loc']]\", \"[['Edge-Loc']]\", \"[['Center']]\", \"[['Edge-Ring']]\",\n",
       "       \"[['Scratch']]\", \"[['Random']]\", \"[['Near-full']]\", \"[['Donut']]\"],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"failureType\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "wafer_map = list(df[\"waferMap\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check shape distribute\n",
    "# shapes = []\n",
    "# for wafer in wafer_map:\n",
    "#     shapes.append(wafer.shape[0])\n",
    "#     shapes.append(wafer.shape[1])\n",
    "# plt.hist(shapes, density=False, color = 'lightblue', cumulative = False, label = \"shapes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7471, 50, 50, 1)\n",
      "(18048, 25, 25, 1)\n"
     ]
    }
   ],
   "source": [
    "small_width = 25\n",
    "small_height = 25\n",
    "\n",
    "big_width = 50\n",
    "big_height = 50\n",
    "\n",
    "x_small = []\n",
    "y_small = []\n",
    "\n",
    "x_big = []\n",
    "y_big = []\n",
    "for i in range(len(wafer_map)):\n",
    "    image = wafer_map[i]\n",
    "    if(image.shape[0] >= big_height or image.shape[1] >= big_width):        \n",
    "        resized = cv2.resize(wafer_map[i], (big_width, big_height), interpolation = cv2.INTER_AREA)\n",
    "        resized = resized.reshape((resized.shape[0], resized.shape[1], 1))\n",
    "        x_big.append(resized)\n",
    "        y_big.append(df.loc[i, \"failureType\"])\n",
    "    else:\n",
    "        resized = cv2.resize(wafer_map[i], (small_width, small_height), interpolation = cv2.INTER_AREA)\n",
    "        resized = resized.reshape((resized.shape[0], resized.shape[1], 1))\n",
    "        x_small.append(resized)\n",
    "        y_small.append(df.loc[i, \"failureType\"])\n",
    "#     # if you want to use transfer learning\n",
    "#     gray_three_channel = cv2.cvtColor(resized, cv2.COLOR_GRAY2BGR)\n",
    "x_big = np.array(x_big)\n",
    "x_small = np.array(x_small)\n",
    "print(x_big.shape)\n",
    "print(x_small.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from sklearn import preprocessing\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, BatchNormalization, Dropout, MaxPooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import layers, models\n",
    "import seaborn\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "le_big = preprocessing.LabelEncoder()\n",
    "y_big = le_big.fit_transform(y_big)\n",
    "classes_num_big = len(le_big.classes_)\n",
    "print(classes_num_big)\n",
    "\n",
    "le_small = preprocessing.LabelEncoder()\n",
    "y_small = le_small.fit_transform(y_small)\n",
    "classes_num_small = len(le_small.classes_)\n",
    "print(classes_num_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4780, 50, 50, 1)\n",
      "(1196, 50, 50, 1)\n",
      "(1495, 50, 50, 1)\n",
      "(11550, 25, 25, 1)\n",
      "(2888, 25, 25, 1)\n",
      "(3610, 25, 25, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train_big, x_test_big, y_train_big, y_test_big = train_test_split(x_big, y_big, test_size=0.2, stratify = y_big, shuffle = True)\n",
    "x_train_big, x_val_big, y_train_big, y_val_big = train_test_split(x_train_big, y_train_big, test_size=0.2, stratify = y_train_big, shuffle = True)\n",
    "print(x_train_big.shape)\n",
    "print(x_val_big.shape)\n",
    "print(x_test_big.shape)\n",
    "\n",
    "x_train_small, x_test_small, y_train_small, y_test_small = train_test_split(x_small, y_small, test_size=0.2, stratify = y_small, shuffle = True)\n",
    "x_train_small, x_val_small, y_train_small, y_val_small = train_test_split(x_train_small, y_train_small, test_size=0.2, stratify = y_train_small, shuffle = True)\n",
    "print(x_train_small.shape)\n",
    "print(x_val_small.shape)\n",
    "print(x_test_small.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # transfer learning\n",
    "# base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape = (width, height, 3))\n",
    "# x = base_model.output\n",
    "# x = GlobalAveragePooling2D()(x)\n",
    "# predictions = Dense(classes_num, activation='softmax')(x)\n",
    "\n",
    "# model = Model(base_model.input, predictions)\n",
    "# model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "# model.summary()\n",
    "# hist = model.fit(x_train, y_train, batch_size = batch_size, epochs=epochs, validation_split = 0.2, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 48, 48, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 24, 24, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 11, 11, 64)        256       \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 1032      \n",
      "=================================================================\n",
      "Total params: 94,600\n",
      "Trainable params: 94,152\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 0.7591 - accuracy: 0.7818 - val_loss: 1.0015 - val_accuracy: 0.7140\n",
      "Epoch 2/50\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.4330 - accuracy: 0.8605 - val_loss: 1.2726 - val_accuracy: 0.6957\n",
      "Epoch 3/50\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.3274 - accuracy: 0.8877 - val_loss: 0.6820 - val_accuracy: 0.7584\n",
      "Epoch 4/50\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.2700 - accuracy: 0.9075 - val_loss: 0.3592 - val_accuracy: 0.8629\n",
      "Epoch 5/50\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.2511 - accuracy: 0.9157 - val_loss: 0.3067 - val_accuracy: 0.8821\n",
      "Epoch 6/50\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.2250 - accuracy: 0.9215 - val_loss: 0.2560 - val_accuracy: 0.9181\n",
      "Epoch 7/50\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.2108 - accuracy: 0.9257 - val_loss: 0.2317 - val_accuracy: 0.9214\n",
      "Epoch 8/50\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.2005 - accuracy: 0.9280 - val_loss: 0.2239 - val_accuracy: 0.9156\n",
      "Epoch 9/50\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.1752 - accuracy: 0.9391 - val_loss: 0.2564 - val_accuracy: 0.8963\n",
      "Epoch 10/50\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.1747 - accuracy: 0.9418 - val_loss: 0.2762 - val_accuracy: 0.8938\n",
      "Epoch 11/50\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.1583 - accuracy: 0.9458 - val_loss: 0.2949 - val_accuracy: 0.8930\n",
      "Epoch 12/50\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.1496 - accuracy: 0.9481 - val_loss: 0.2158 - val_accuracy: 0.9206\n",
      "Epoch 13/50\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.1384 - accuracy: 0.9531 - val_loss: 0.2602 - val_accuracy: 0.9164\n",
      "Epoch 14/50\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.1338 - accuracy: 0.9554 - val_loss: 0.6883 - val_accuracy: 0.8470\n",
      "Epoch 15/50\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.1316 - accuracy: 0.9538 - val_loss: 2.8567 - val_accuracy: 0.3119\n",
      "Epoch 16/50\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.1135 - accuracy: 0.9649 - val_loss: 0.2868 - val_accuracy: 0.8988\n",
      "Epoch 17/50\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.1123 - accuracy: 0.9592 - val_loss: 0.2622 - val_accuracy: 0.9139\n",
      "Epoch 18/50\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.1066 - accuracy: 0.9653 - val_loss: 0.2080 - val_accuracy: 0.9214\n",
      "Epoch 19/50\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.0939 - accuracy: 0.9680 - val_loss: 0.2329 - val_accuracy: 0.9197\n",
      "Epoch 20/50\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.1009 - accuracy: 0.9646 - val_loss: 0.1834 - val_accuracy: 0.9398\n",
      "Epoch 21/50\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.0927 - accuracy: 0.9684 - val_loss: 0.2983 - val_accuracy: 0.9022\n",
      "Epoch 22/50\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.0863 - accuracy: 0.9747 - val_loss: 0.2174 - val_accuracy: 0.9339\n",
      "Epoch 23/50\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.0880 - accuracy: 0.9711 - val_loss: 0.1651 - val_accuracy: 0.9431\n",
      "Epoch 24/50\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.0760 - accuracy: 0.9753 - val_loss: 0.3078 - val_accuracy: 0.9038\n",
      "Epoch 25/50\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.0763 - accuracy: 0.9738 - val_loss: 0.3863 - val_accuracy: 0.8788\n",
      "Epoch 26/50\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.0742 - accuracy: 0.9776 - val_loss: 0.2069 - val_accuracy: 0.9273\n",
      "Epoch 27/50\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.0620 - accuracy: 0.9801 - val_loss: 0.2202 - val_accuracy: 0.9314\n",
      "Epoch 28/50\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.0649 - accuracy: 0.9782 - val_loss: 0.2784 - val_accuracy: 0.9064\n",
      "Epoch 29/50\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.0659 - accuracy: 0.9774 - val_loss: 0.3103 - val_accuracy: 0.9156\n",
      "Epoch 30/50\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.0649 - accuracy: 0.9808 - val_loss: 0.1892 - val_accuracy: 0.9381\n",
      "Epoch 31/50\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.0603 - accuracy: 0.9795 - val_loss: 0.2112 - val_accuracy: 0.9239\n",
      "Epoch 32/50\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.0658 - accuracy: 0.9787 - val_loss: 0.2744 - val_accuracy: 0.9247\n",
      "Epoch 33/50\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.0595 - accuracy: 0.9805 - val_loss: 0.1798 - val_accuracy: 0.9457\n",
      "Epoch 34/50\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.0594 - accuracy: 0.9808 - val_loss: 0.2228 - val_accuracy: 0.9448\n",
      "Epoch 35/50\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.0553 - accuracy: 0.9824 - val_loss: 0.3472 - val_accuracy: 0.9089\n",
      "Epoch 36/50\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.0555 - accuracy: 0.9822 - val_loss: 0.2315 - val_accuracy: 0.9264\n",
      "Epoch 37/50\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.0511 - accuracy: 0.9837 - val_loss: 0.2920 - val_accuracy: 0.9231\n",
      "Epoch 38/50\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.0471 - accuracy: 0.9843 - val_loss: 0.2132 - val_accuracy: 0.9390\n",
      "Epoch 39/50\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.0423 - accuracy: 0.9879 - val_loss: 0.1902 - val_accuracy: 0.9440\n",
      "Epoch 40/50\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.0387 - accuracy: 0.9893 - val_loss: 0.3929 - val_accuracy: 0.8988\n",
      "Epoch 41/50\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.0430 - accuracy: 0.9845 - val_loss: 0.4620 - val_accuracy: 0.8963\n",
      "Epoch 42/50\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.0578 - accuracy: 0.9787 - val_loss: 0.3293 - val_accuracy: 0.9114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/50\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.0389 - accuracy: 0.9902 - val_loss: 0.2082 - val_accuracy: 0.9373\n",
      "Epoch 44/50\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.0511 - accuracy: 0.9824 - val_loss: 0.2118 - val_accuracy: 0.9406\n",
      "Epoch 45/50\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0397 - accuracy: 0.98 - 1s 7ms/step - loss: 0.0405 - accuracy: 0.9883 - val_loss: 0.4432 - val_accuracy: 0.9089\n",
      "Epoch 46/50\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.0387 - accuracy: 0.9879 - val_loss: 0.3188 - val_accuracy: 0.9064\n",
      "Epoch 47/50\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.0344 - accuracy: 0.9885 - val_loss: 0.2341 - val_accuracy: 0.9381\n",
      "Epoch 48/50\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.0382 - accuracy: 0.9889 - val_loss: 0.2276 - val_accuracy: 0.9331\n",
      "Epoch 49/50\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.0365 - accuracy: 0.9868 - val_loss: 0.2402 - val_accuracy: 0.9356\n",
      "Epoch 50/50\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.0372 - accuracy: 0.9866 - val_loss: 0.3072 - val_accuracy: 0.9147\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "batch_size = 32\n",
    "model_big = models.Sequential()\n",
    "model_big.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(big_width, big_height, 1)))\n",
    "model_big.add(MaxPooling2D((2, 2)))\n",
    "model_big.add(BatchNormalization())\n",
    "model_big.add(Dropout(0.2))\n",
    "model_big.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model_big.add(MaxPooling2D((2, 2)))\n",
    "model_big.add(BatchNormalization())\n",
    "model_big.add(Dropout(0.2))\n",
    "model_big.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model_big.add(MaxPooling2D((2, 2)))\n",
    "model_big.add(BatchNormalization())\n",
    "model_big.add(Dropout(0.2))\n",
    "model_big.add(GlobalAveragePooling2D())\n",
    "model_big.add(layers.Dense(classes_num_big, activation='softmax'))\n",
    "model_big.summary()\n",
    "model_big.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "hist = model_big.fit(x_train_big, y_train_big, batch_size = batch_size, epochs=epochs, validation_data = (x_val_big, y_val_big), shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_38 (Conv2D)           (None, 23, 23, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 11, 11, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 11, 11, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 9, 9, 64)          18496     \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 9, 9, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_40 (Conv2D)           (None, 7, 7, 128)         73856     \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 5, 5, 256)         295168    \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_10  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 8)                 2056      \n",
      "=================================================================\n",
      "Total params: 389,896\n",
      "Trainable params: 389,896\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "2888/2888 [==============================] - 9s 3ms/step - loss: 1.0743 - accuracy: 0.5860 - val_loss: 0.6651 - val_accuracy: 0.7503\n",
      "Epoch 2/50\n",
      "2888/2888 [==============================] - 9s 3ms/step - loss: 0.6504 - accuracy: 0.7601 - val_loss: 0.6141 - val_accuracy: 0.7704\n",
      "Epoch 3/50\n",
      "2888/2888 [==============================] - 9s 3ms/step - loss: 0.5672 - accuracy: 0.7835 - val_loss: 0.5502 - val_accuracy: 0.7957\n",
      "Epoch 4/50\n",
      "2888/2888 [==============================] - 9s 3ms/step - loss: 0.5264 - accuracy: 0.8035 - val_loss: 0.5463 - val_accuracy: 0.8037\n",
      "Epoch 5/50\n",
      "2888/2888 [==============================] - 9s 3ms/step - loss: 0.4845 - accuracy: 0.8192 - val_loss: 0.5169 - val_accuracy: 0.8127\n",
      "Epoch 6/50\n",
      "2888/2888 [==============================] - 9s 3ms/step - loss: 0.4585 - accuracy: 0.8255 - val_loss: 0.4605 - val_accuracy: 0.8373\n",
      "Epoch 7/50\n",
      "2888/2888 [==============================] - 9s 3ms/step - loss: 0.4369 - accuracy: 0.8351 - val_loss: 0.4661 - val_accuracy: 0.8328\n",
      "Epoch 8/50\n",
      "2888/2888 [==============================] - 9s 3ms/step - loss: 0.4168 - accuracy: 0.8408 - val_loss: 0.4283 - val_accuracy: 0.8414\n",
      "Epoch 9/50\n",
      "2888/2888 [==============================] - 9s 3ms/step - loss: 0.4016 - accuracy: 0.8534 - val_loss: 0.4226 - val_accuracy: 0.8428\n",
      "Epoch 10/50\n",
      "2888/2888 [==============================] - 9s 3ms/step - loss: 0.3845 - accuracy: 0.8563 - val_loss: 0.4320 - val_accuracy: 0.8341\n",
      "Epoch 11/50\n",
      "2888/2888 [==============================] - 9s 3ms/step - loss: 0.3664 - accuracy: 0.8623 - val_loss: 0.4144 - val_accuracy: 0.8508\n",
      "Epoch 12/50\n",
      "2888/2888 [==============================] - 9s 3ms/step - loss: 0.3527 - accuracy: 0.8698 - val_loss: 0.4010 - val_accuracy: 0.8608\n",
      "Epoch 13/50\n",
      "2888/2888 [==============================] - 9s 3ms/step - loss: 0.3375 - accuracy: 0.8764 - val_loss: 0.4390 - val_accuracy: 0.8390\n",
      "Epoch 14/50\n",
      "2888/2888 [==============================] - 9s 3ms/step - loss: 0.3319 - accuracy: 0.8782 - val_loss: 0.3962 - val_accuracy: 0.8580\n",
      "Epoch 15/50\n",
      "2888/2888 [==============================] - 9s 3ms/step - loss: 0.3160 - accuracy: 0.8842 - val_loss: 0.4030 - val_accuracy: 0.8542\n",
      "Epoch 16/50\n",
      "2888/2888 [==============================] - 9s 3ms/step - loss: 0.3043 - accuracy: 0.8868 - val_loss: 0.4039 - val_accuracy: 0.8601\n",
      "Epoch 17/50\n",
      "2888/2888 [==============================] - 9s 3ms/step - loss: 0.2919 - accuracy: 0.8952 - val_loss: 0.4271 - val_accuracy: 0.8556\n",
      "Epoch 18/50\n",
      "2888/2888 [==============================] - 9s 3ms/step - loss: 0.2842 - accuracy: 0.8914 - val_loss: 0.4279 - val_accuracy: 0.8452\n",
      "Epoch 19/50\n",
      "2888/2888 [==============================] - 9s 3ms/step - loss: 0.2796 - accuracy: 0.8930 - val_loss: 0.3889 - val_accuracy: 0.8563\n",
      "Epoch 20/50\n",
      "2888/2888 [==============================] - 9s 3ms/step - loss: 0.2663 - accuracy: 0.9009 - val_loss: 0.4033 - val_accuracy: 0.8560\n",
      "Epoch 21/50\n",
      "2888/2888 [==============================] - 9s 3ms/step - loss: 0.2701 - accuracy: 0.9011 - val_loss: 0.4089 - val_accuracy: 0.8643\n",
      "Epoch 22/50\n",
      "2888/2888 [==============================] - 9s 3ms/step - loss: 0.2522 - accuracy: 0.9038 - val_loss: 0.4512 - val_accuracy: 0.8546\n",
      "Epoch 23/50\n",
      "2888/2888 [==============================] - 9s 3ms/step - loss: 0.2472 - accuracy: 0.9099 - val_loss: 0.4227 - val_accuracy: 0.8608\n",
      "Epoch 24/50\n",
      "2888/2888 [==============================] - 9s 3ms/step - loss: 0.2392 - accuracy: 0.9130 - val_loss: 0.4615 - val_accuracy: 0.8425\n",
      "Epoch 25/50\n",
      "2888/2888 [==============================] - 9s 3ms/step - loss: 0.2368 - accuracy: 0.9126 - val_loss: 0.4547 - val_accuracy: 0.8428\n",
      "Epoch 26/50\n",
      "2888/2888 [==============================] - 9s 3ms/step - loss: 0.2348 - accuracy: 0.9139 - val_loss: 0.4610 - val_accuracy: 0.8428\n",
      "Epoch 27/50\n",
      "2888/2888 [==============================] - 9s 3ms/step - loss: 0.2221 - accuracy: 0.9171 - val_loss: 0.4152 - val_accuracy: 0.8601\n",
      "Epoch 28/50\n",
      "2888/2888 [==============================] - 9s 3ms/step - loss: 0.2322 - accuracy: 0.9172 - val_loss: 0.3921 - val_accuracy: 0.8646\n",
      "Epoch 29/50\n",
      "2888/2888 [==============================] - 9s 3ms/step - loss: 0.2201 - accuracy: 0.9187 - val_loss: 0.5086 - val_accuracy: 0.8511\n",
      "Epoch 30/50\n",
      "2888/2888 [==============================] - 9s 3ms/step - loss: 0.2188 - accuracy: 0.9217 - val_loss: 0.4691 - val_accuracy: 0.8587\n",
      "Epoch 31/50\n",
      "2888/2888 [==============================] - 9s 3ms/step - loss: 0.2147 - accuracy: 0.9214 - val_loss: 0.4148 - val_accuracy: 0.8674\n",
      "Epoch 32/50\n",
      "2888/2888 [==============================] - 9s 3ms/step - loss: 0.2033 - accuracy: 0.9274 - val_loss: 0.4417 - val_accuracy: 0.8643\n",
      "Epoch 33/50\n",
      "2888/2888 [==============================] - 9s 3ms/step - loss: 0.2018 - accuracy: 0.9260 - val_loss: 0.4416 - val_accuracy: 0.8504\n",
      "Epoch 34/50\n",
      "2888/2888 [==============================] - 9s 3ms/step - loss: 0.1945 - accuracy: 0.9294 - val_loss: 0.5222 - val_accuracy: 0.8518\n",
      "Epoch 35/50\n",
      "2888/2888 [==============================] - 9s 3ms/step - loss: 0.2008 - accuracy: 0.9290 - val_loss: 0.4850 - val_accuracy: 0.8636\n",
      "Epoch 36/50\n",
      "2888/2888 [==============================] - 9s 3ms/step - loss: 0.2097 - accuracy: 0.9258 - val_loss: 0.4553 - val_accuracy: 0.8660\n",
      "Epoch 37/50\n",
      "2888/2888 [==============================] - 9s 3ms/step - loss: 0.1929 - accuracy: 0.9295 - val_loss: 0.4805 - val_accuracy: 0.8539\n",
      "Epoch 38/50\n",
      "2888/2888 [==============================] - 9s 3ms/step - loss: 0.1912 - accuracy: 0.9320 - val_loss: 0.4452 - val_accuracy: 0.8591\n",
      "Epoch 39/50\n",
      "2888/2888 [==============================] - 9s 3ms/step - loss: 0.1838 - accuracy: 0.9340 - val_loss: 0.4613 - val_accuracy: 0.8674\n",
      "Epoch 40/50\n",
      "2888/2888 [==============================] - 9s 3ms/step - loss: 0.1910 - accuracy: 0.9319 - val_loss: 0.5763 - val_accuracy: 0.8490\n",
      "Epoch 41/50\n",
      "2888/2888 [==============================] - 9s 3ms/step - loss: 0.1781 - accuracy: 0.9361 - val_loss: 0.4820 - val_accuracy: 0.8657\n",
      "Epoch 42/50\n",
      "2888/2888 [==============================] - 9s 3ms/step - loss: 0.1768 - accuracy: 0.9363 - val_loss: 0.5301 - val_accuracy: 0.8480\n",
      "Epoch 43/50\n",
      "2888/2888 [==============================] - 9s 3ms/step - loss: 0.1841 - accuracy: 0.9337 - val_loss: 0.5258 - val_accuracy: 0.8584\n",
      "Epoch 44/50\n",
      "2880/2888 [============================>.] - ETA: 0s - loss: 0.1826 - accuracy: 0.9349"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-841b966be08d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mmodel_small\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mmodel_small\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"adam\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"sparse_categorical_crossentropy\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"accuracy\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mhist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_small\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train_small\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_small\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx_val_small\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val_small\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1131\u001b[0m               \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1133\u001b[1;33m               return_dict=True)\n\u001b[0m\u001b[0;32m   1134\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'val_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mval\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1135\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[0;32m   1382\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[1;31m# No error, now safe to assign to logs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1383\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1384\u001b[1;33m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_test_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1385\u001b[0m       \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1386\u001b[0m       \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_test_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_test_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    460\u001b[0m     \"\"\"\n\u001b[0;32m    461\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_should_call_test_batch_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTEST\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_predict_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    287\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 289\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    290\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Unrecognized hook: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    307\u001b[0m       \u001b[0mbatch_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 309\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    310\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    343\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Only convert once.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m           \u001b[0mnumpy_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m         \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumpy_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    535\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 537\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    538\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 635\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 635\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    531\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    532\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 533\u001b[1;33m       \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    534\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    535\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1061\u001b[0m     \"\"\"\n\u001b[0;32m   1062\u001b[0m     \u001b[1;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1063\u001b[1;33m     \u001b[0mmaybe_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1064\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1065\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1027\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1028\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1029\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1030\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m       \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "batch_size = 32\n",
    "model_small = models.Sequential()\n",
    "model_small.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(small_width, small_height, 1)))\n",
    "model_small.add(MaxPooling2D((2, 2)))\n",
    "model_small.add(BatchNormalization())\n",
    "model_small.add(Dropout(0.2))\n",
    "model_small.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model_small.add(BatchNormalization())\n",
    "model_small.add(Dropout(0.2))\n",
    "model_small.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model_small.add(BatchNormalization())\n",
    "model_small.add(Dropout(0.2))\n",
    "model_small.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
    "model_small.add(BatchNormalization())\n",
    "model_small.add(Dropout(0.2))\n",
    "model_small.add(GlobalAveragePooling2D())\n",
    "model_small.add(layers.Dense(classes_num_small, activation='softmax'))\n",
    "model_small.summary()\n",
    "model_small.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "hist = model_small.fit(x_train_small, y_train_small, batch_size = batch_size, epochs=epochs, validation_data = (x_val_small, y_val_small), shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss, accuracy = model.evaluate(x_test, y_test)\n",
    "# print(f\"accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# array = confusion_matrix(y_test, model.predict_classes(x_test))\n",
    "# df_cm = pd.DataFrame(array, index = [i for i in le.classes_], columns = [i for i in le.classes_])\n",
    "# df_norm_col=(df-df.mean())/df.std()\n",
    "\n",
    "# plt.figure(figsize = (10,7))\n",
    "# seaborn.heatmap(df_cm, annot=True, fmt=\"d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
